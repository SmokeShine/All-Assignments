{
  "cells": [
    {
      "metadata": {
        "_uuid": "3d77e668b4496706e475180790c8a4a4f9f4b905"
      },
      "cell_type": "markdown",
      "source": "# Project Overview\nThis project aims to identify and classify a toxic comment during online conversation. Social networking sites and user groups allow people to come together and have an open discussion on topics they care about. Platforms intend to facilitate conversations without being harassed by people with different opinions. Certain platforms differentiate themselves by allowing mature conversations, while discouraging harsh comments.\nThis is a case of a multi label classification problem, which can be tackled by using Supervised learning algorithms. \n"
    },
    {
      "metadata": {
        "_uuid": "a10fdfaa91b123be8200a327d81eee0d2550fc82"
      },
      "cell_type": "markdown",
      "source": "# Step 1: Importing Libraries\nMain Packages Used:\n* Pandas – 0.22.0\n* Numpy – 1.14.2\n* Sklearn – 0.19.1\n* Keras – 2.1.5 "
    },
    {
      "metadata": {
        "_uuid": "7bc55c06425098e4cdf3b0c70590be8a8694f7e3"
      },
      "cell_type": "markdown",
      "source": "# Modules for Importing Data"
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Udacity Machine Learning Capstone\n\nimport time\n#Data Importing Modules\nimport pandas as pd\nimport numpy as np\nnp.random.seed(42)\nimport string\nimport re\nfrom collections import Counter\nimport pickle\nimport tensorflow as tf",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "85913df787b7b73aade646d3d5f9bf47973e38ee"
      },
      "cell_type": "markdown",
      "source": "# Sklearn Libraries"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9076a36a1b5fe0727ec2ed51fac90a704f9d663b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Selective Sklearn Libraries\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Dropout, Conv1D, Embedding, SpatialDropout1D, concatenate\nfrom keras.layers import GRU, LSTM,Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\nfrom keras.layers import CuDNNLSTM, CuDNNGRU\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import Callback\nfrom keras import optimizers\nfrom keras.layers import Lambda\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom nltk.corpus import stopwords\nimport os\nos.environ['OMP_NUM_THREADS'] = '4'\nimport gc\nfrom keras import backend as K\nfrom sklearn.model_selection import KFold",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0e530f8ba2298b3b5c9f9e9fb7eff9a408e744a1"
      },
      "cell_type": "markdown",
      "source": "# Text Cleaning Modules"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c05027fc73cf23140c06ec881a37d6a75948f617",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Text Cleaning Module\nfrom unidecode import unidecode\neng_stopwords = set(stopwords.words(\"english\"))",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7e61a028070452815c2a2d81dbbea3021a1980eb"
      },
      "cell_type": "markdown",
      "source": "# Visualization Libraries"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d12fd806ea6d8ab10248773f1c174659b3a6232b"
      },
      "cell_type": "code",
      "source": "#Visualization Libraries\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\nfrom matplotlib_venn import venn3\n\nfrom wordcloud import WordCloud",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "22682bbfba5f607d06859043743228ab3170c00a"
      },
      "cell_type": "markdown",
      "source": "# Step 2: Reading Input Data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "301730c61ffd52812db0cb0a29b5c65c31378826",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#reading all input files\n\n# train\nprint(\"reading train files\")\ntrain = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv',encoding='utf-8')\n#test\nprint (\"Now reading test files\")\ntest=pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv',encoding='utf-8')",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "828ae418063587d30253678bd4b3cba2fe324454"
      },
      "cell_type": "markdown",
      "source": "\n# File descriptions \n1.\tKaggle Files\n\ntrain.csv - the training set, contains comments with their binary labels \n\ntest.csv - the test set \n\t\n2.\tAdditional Files \n\na.\tGloVe Twitter - unsupervised learning algorithm for obtaining vector representations for words - https://nlp.stanford.edu/projects/glove/\n\nData Description \n\n1.\tColumns in train.csv and test.csv\n\na.\tId – unique identifier\n\nb.\tComment_text – comment by users\n\nc.\tToxic – binary labels for toxic classification\n\nd.\tsevere_toxic – binary labels for severe toxic classification\n\ne.\tobscene – binary labels for obscene classification\n\nf.\tthreat – binary labels for threat classification\n\ng.\tinsult – binary labels for insult classification\n\nh.\tidentity_hate – binary labels for identity hate classification\n\n\t#Columns – 2\n\t#Rows-153164\n\tThis data is highly relevant as we need this data to test the performance of model on unseen data \n2.\tIn train.csv\n\na.\t#Columns – 8\n\nb.\t#Rows – 15957\n\nc.\tThis data is highly relevant as we need to train on this data to make classification\n\n3.\tIn test.csv \n\na.\t#Columns – 2\n\nb.\t#Rows-153164\n\nc.\tThis data is highly relevant as we need this data to test the performance of model on unseen data"
    },
    {
      "metadata": {
        "_uuid": "298c246f249e654c14d14e7d3fe19f5dc9ae401f"
      },
      "cell_type": "markdown",
      "source": "# Data Cleaning\nThe data for natural language processing is highly unstructured and noisy in nature. To achieve better insights and build algorithms, it is necessary to clean the data\nFiles will have to cleaned as there are contains non utf-8 characters present in the columns"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8aeadda69f401e1fa4e75a5780fc337e32002bf9",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#files will have to cleaned- contains non utf-8 characters\ntrain = train.replace(r'\\n',' ', regex=True)\ntrain = train.replace(r'\\\\',' ', regex=True)\nprint (train.head())\n\n\n#Filters out punctuation (filters=’!”#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n’).\n\n#special_character_removal = re.compile(r'[!\"#$%&()*,-./:;<=>?@[\\\\]^_`{|}~\\t\\n]',re.IGNORECASE)\nspecial_character_removal = re.compile(r'[^A-Za-z\\.\\-\\?\\!\\,\\#\\@\\% ]',re.IGNORECASE)\ndef clean_text(x):\n    x_ascii = unidecode(x)\n    x_clean = special_character_removal.sub('',x_ascii)\n    return x_clean\n\ntrain['clean_text'] = train['comment_text'].apply(lambda x: clean_text(str(x)))\ntest['clean_text'] = test['comment_text'].apply(lambda x: clean_text(str(x)))\n\nX_train = train['clean_text'].fillna(\"something\").values\ny_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\nX_test = test['clean_text'].fillna(\"something\").values\n",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8fed66796e977232b6db9bffbf70d2b75dc3135d"
      },
      "cell_type": "markdown",
      "source": "# Step 3: Adding Features\nWe will add columns such as caps_vs_length and words_vs_unique which will be later used as an input in the model\nWe will further standardize it using sklearn's StandardScaler module"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f002dd61973077089e4f3603e61cd267b011455f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#adding features\ndef add_features(df):\n    \n    df['comment_text'] = df['comment_text'].apply(lambda x:str(x))\n    df['total_length'] = df['comment_text'].apply(len)\n    df['capitals'] = df['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n    df['caps_vs_length'] = df.apply(lambda row: float(row['capitals'])/float(row['total_length']),\n                                axis=1)\n    df['num_words'] = df.comment_text.str.count('\\S+')\n    df['num_unique_words'] = df['comment_text'].apply(lambda comment: len(set(w for w in comment.split())))\n    df['words_vs_unique'] = df['num_unique_words'] / df['num_words']  \n\n    return df\n\ntrain = add_features(train)\ntest = add_features(test)\n\nfeatures = train[['caps_vs_length', 'words_vs_unique']].fillna(0)\ntest_features = test[['caps_vs_length', 'words_vs_unique']].fillna(0)\n\n#Using Standard Scaler to get z score\nfrom sklearn.preprocessing import StandardScaler\n\nss = StandardScaler()\nss.fit(np.vstack((features, test_features)))\nfeatures = ss.transform(features)\ntest_features = ss.transform(test_features)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "798649c72efdbaedcafac669ab07dab0af3103a6"
      },
      "cell_type": "markdown",
      "source": "# Step 4: Exploratory Data Analysis\nIn this step, we will try to understand the data and see the distribution of different labels\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "23d27970a361517a451dd745013afc7a65941c06",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Basic EDA\nCOLUMNS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n\n#Creating a copy for wordcloud\nCATEGORIES = COLUMNS.copy()\n\nprint(\"Sample Data\")\nprint (train.head())\n\ntrain_distribution = train[COLUMNS].sum()\\\n                            .to_frame()\\\n                            .rename(columns={0: 'count'})\\\n                            .sort_values('count')\n\ntrain_distribution.sort_values('count', ascending=False)    ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8ff7527629dc50586eb667fe3fbd8a0e9d764b7d"
      },
      "cell_type": "markdown",
      "source": "From the data, we see that  the three major labels are :\ntoxic, obscene and insult\nOther labels have a very small quantum"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "70cd20b824f080de669078b67d1bd7ce2213659f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_comb = train.groupby(COLUMNS)\\\n                    .size()\\\n                    .sort_values(ascending=False)\\\n                    .reset_index()\\\n                    .rename(columns={0: 'count'})\ntrain_comb.head(n=10)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7d5275fc9241c31dea8ea5dadc5d93e0b2a9fbc1"
      },
      "cell_type": "markdown",
      "source": "Here, we are checking for class imbalances. From this table, we know that some comments can fall in multiple categories."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "338bb6629dac7f1f3d1a3cead4d29ea5180f94d2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Correlation Matrix\nf, ax = plt.subplots(figsize=(9, 6))\nf.suptitle('Correlation matrix for categories')\nsns.heatmap(train[COLUMNS].corr(), annot=True, linewidths=.5, ax=ax)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "160ae2f4e1ec0109a1a973dcd1ecd668aff17b61",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train[COLUMNS].corr().abs().unstack().sort_values(ascending=False)",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3e8c637a3d69a4766524b1744eb1156c050c9bca"
      },
      "cell_type": "markdown",
      "source": "From these  graphs, we find that insult, obscene and toxic are highly correlated to each other."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aa5609c4097506f635f20f9d7bac878c965d1fa2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Correlation matrix of added features\n\nCOLUMNS=COLUMNS+['total_length','caps_vs_length', 'num_words','num_unique_words','words_vs_unique']\nf, ax = plt.subplots(figsize=(20, 20))\nf.suptitle('Correlation matrix for categories and features')\nsns.heatmap(train[COLUMNS].corr(), annot=True, linewidths=.5, ax=ax)",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8c7b4182d977b383000cca07d0c2325e9f3094a9"
      },
      "cell_type": "markdown",
      "source": "# Creating Word Cloud for Free Form Visualization"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "5434ffb0c5d85004be5aeafdb161a51ed8eb796f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Creating word cloud \nword_counter = {}\ndef clean_text(text):\n    text = re.sub('[{}]'.format(string.punctuation), ' ', text.lower())\n    return ' '.join([word for word in text.split() if word not in (eng_stopwords)])\n\nfor categ in CATEGORIES:\n    d = Counter()\n    train[train[categ] == 1]['comment_text'].apply(lambda t: d.update(clean_text(t).split()))\n    word_counter[categ] = pd.DataFrame.from_dict(d, orient='index')\\\n                                        .rename(columns={0: 'count'})\\\n                                        .sort_values('count', ascending=False)\nfor w in word_counter:\n    wc = word_counter[w]\n\n    wordcloud = WordCloud(\n          background_color='black',\n          max_words=200,\n          max_font_size=100, \n          random_state=4561\n         ).generate_from_frequencies(wc.to_dict()['count'])\n\n    fig = plt.figure(figsize=(12, 8))\n    plt.title(w)\n    plt.imshow(wordcloud)\n    plt.axis('off')\n\n    plt.show()            ",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5a46105502bf1f1eb9c41a382a41aa855d0d7ac8"
      },
      "cell_type": "markdown",
      "source": "# Step 5: Tokenize text\nIn this step, we will tokenizing the data so that it can be used be fed into the model\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "65e8f89b7fc16d06a6effbb2300b7a20f87b37f7",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from keras.preprocessing import text, sequence\n\n#https://machinelearningmastery.com/prepare-text-data-deep-learning-keras/\n#Keras provides the text_to_word_sequence() function that you can use to split text into a list of words.\nmax_features=20000\nmaxlen = 50\n\ntokenizer = text.Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(X_train) + list(X_test))\n\nX_train_sequence = tokenizer.texts_to_sequences(X_train)\nX_test_sequence = tokenizer.texts_to_sequences(X_test)\n\nx_train = sequence.pad_sequences(X_train_sequence, maxlen=maxlen)\nx_test = sequence.pad_sequences(X_test_sequence, maxlen=maxlen)\n#print(tokenizer.word_index)\n\n\n#word index created, each word will have an index\n# pass words through embedding to get corresponding values\n",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ea62ba3811c99fb371abc388646948d18125ae53",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "max_features=20000\nmaxlen = 50",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4dfed98d0cc62bc90c33de5e080ec142c0a9b00e"
      },
      "cell_type": "markdown",
      "source": "# Step 5: Embedding Layer\n\nWe now want to use GloVe twitter data as vocubulary and get corresponsing embedding matrix"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e176a548ace8eea2530b36b2640b3c8582561930",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import csv\n\n#Reference: https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/\n# load embedding as a dict\nword_index = tokenizer.word_index\nnb_words = min(max_features, len(word_index))\nembedding_vectors = np.zeros((nb_words,501))\n\ndef load_embedding(filename):\n    file = open(filename,'r')\n    lines = file.readlines()\n    file.close()\n    embedding = dict()\n    for line in lines:\n        parts = line.split()\n        embedding[parts[0]] = np.asarray(parts[1:], dtype='float32')\n    return embedding\n\ndef get_weight_matrix(embedding, vocab):\n# total vocabulary size plus 0 for unknown words\n    #controlling vocab size using max features\n    vocab_size = len(vocab) + 1\n    # define weight matrix dimensions with all 0\n    weight_matrix = np.zeros((vocab_size, 200))\n    # step vocab, store vectors using the Tokenizer's integer mapping\n    for word, i in vocab.items():\n        vector = embedding.get(word)\n        if vector is not None:\n            weight_matrix[i] = vector\n    return weight_matrix\n\nraw_embedding = load_embedding('../input/glove-twitter-27b-200d-txt/glove.twitter.27B.200d.txt')\n\n# get vectors in the right order #taking only count till nb_words\nembedding_vectors = get_weight_matrix(raw_embedding, tokenizer.word_index)[:nb_words,:] #Will be used to create embedding layer",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3949d2da1b15190a7ae3b400e020fc95fa64568f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#testing embedding data\nprint(list(tokenizer.word_counts.keys())[:2])\nprint(list(tokenizer.word_index.keys())[:2]) # emdding vector will align to word index and now to word doc or word counts\nprint(list(tokenizer.word_docs.keys())[:2])",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98b0cfac34500d1f0c7eab67ad025fe2ba345552",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#sum(raw_embedding['explanation']==embedding_vectors[1] returns zero\nprint(\"Embedding Load Check \",sum(raw_embedding['the']==embedding_vectors[1])) #returns 200 - same as dimension of glove data 200d\n#sum(raw_embedding['after']==embedding_vectors[1]) returns zero\n\nraw_embedding['hate']",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2c06daa42b381af947e900a7beb765da2f768785"
      },
      "cell_type": "markdown",
      "source": "# Base Accuracy - Predicting all labels as non toxic"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "711baffce97205e9795b0530b59054f04b5dc77d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Base Accuracy - Predicting all labels as non toxic\n# using train_comb\nprint(\"Base Accuracy - Predicting all labels as non toxic \")\n(1-train_comb[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].mean())*100.0",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ff221d771d5878567cb9f14e390b8164e8fd7656"
      },
      "cell_type": "markdown",
      "source": "For an unbalanced classification problem, marking everything as non toxic will give the above accuracies. Our neural model needs to work better than the base accuracy"
    },
    {
      "metadata": {
        "_uuid": "af103c5ca6cc59a3280c8b470204d10c695a69ac"
      },
      "cell_type": "markdown",
      "source": "# Step 6: Model Implementation\n\nFor this problem, we intend to use recurrent neural network. Persistence of information is important for understanding context from a sentence. Traditional neural networks do not have this capability. RNN (Recurrent neural network) can address this issue by allowing information to pass through loops. In cases, where the gap between the relevant information and the place where it is needed is small, RNN can be used to learn past information\n\nLSTM (Long Short Term Memory) is a special type of RNN, which can learn to connect the information with long term dependencies. \nGRU (Gated Recurrent Unit) uses gating mechanism in RNN. The absence of output gate reduces the number of parameters as that of LSTM and provides better performance over LSTM over smaller datasets."
    },
    {
      "metadata": {
        "_uuid": "20020fe382b0a15530edaa77a80cb0cfa2d721f3"
      },
      "cell_type": "markdown",
      "source": "# ROC AUC Score\n\nROC is used to understand how to balance false positives and false negatives. For an imbalanced classification problem, accuracy as an evaluation metric, does not consider in-class misclassification. For example, marking all comments as nontoxic, may give us a good overall accuracy, but the model may work very poorly for identifying individual classes.\n\nROCx(θ)=False Positive Rate(θ)=(False Positive(θ))/(False Positive(θ)+True Negative(θ))\n  \nROCy(θ)=True Positive Rate(θ)=(True Positive(θ))/(False Negative(θ)+True Positive(θ) )\nIn terms of hypothesis testing where rejecting the null hypothesis is considered a positive result, the False Positive Rate corresponds to Type I error, the False Negative Rate corresponds to Type II error.\nPlotting True Positive Rate against False Positive Rate, gives us the ROC curve. Calculating area under the curve (AUC) can be used to score the model. An excellent model should score value very close to 1.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "1cb60dba26e46c6daed2a1eeabe887c42506a2eb"
      },
      "cell_type": "code",
      "source": "# ROC - Boiler Plate Code\n\nclass RocAucEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n        self.max_score = 0\n        self.not_better_count = 0\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=1)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n            if (score > self.max_score):\n                print(\"*** New High Score (previous: %.6f) \\n\" % self.max_score)\n                model.save_weights(\"best_weights.h5\")\n                self.max_score=score\n                self.not_better_count = 0\n            else:\n                self.not_better_count += 1\n                if self.not_better_count > 3:\n                    print(\"Epoch %05d: early stopping, high score = %.6f\" % (epoch,self.max_score))\n                    self.model.stop_training = True",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3a26d0a783621105a0aa66fc69681342bf004f14",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def get_model(features,clipvalue=1.,num_filters=40,dropout=0.5,embed_size=200):\n    features_input = Input(shape=(features.shape[1],))\n    inp = Input(shape=(maxlen, ))    \n    x = Embedding(max_features, embed_size, weights=[embedding_vectors], trainable=False,name='EmbeddingLayer')(inp)\n    #x = SpatialDropout1D(dropout)(x)\n    #x = Bidirectional(LSTM(num_filters, return_sequences=True),name='BidirectionalLSTM')(x)\n    x, x_h, x_c = Bidirectional(GRU(num_filters, return_sequences=True, return_state = True),name='BidirectionalGRU')(x)  \n    avg_pool = GlobalAveragePooling1D()(x)\n    max_pool = GlobalMaxPooling1D()(x)    \n    x = concatenate([avg_pool, x_h, max_pool,features_input])\n    outp = Dense(6, activation=\"sigmoid\")(x)\n    model = Model(inputs=[inp,features_input], outputs=outp)\n    adam = optimizers.adam(clipvalue=clipvalue)\n    model.compile(loss='binary_crossentropy',\n                  optimizer=adam,\n                  metrics=['accuracy'])\n    return model",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0cd8a3d03dfd88879f826afa6176093cf8f93cf6"
      },
      "cell_type": "markdown",
      "source": "In this step, we will visualize the Deep Learning model. Further, we will be setting the parameters for epochs, batch size and num_folds here. This will be used for tuning the model\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5c51fab9e075c95d9f7b6084be7d514ab0c7276c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "get_model(features).summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "356095a2247590bccefb2d12bbec284ae2da268c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model = get_model(features)\nbatch_size = 32\nepochs = 5\ngc.collect()\nK.clear_session()\nnum_folds = 5 \npredict = np.zeros((test.shape[0],6))\nscores = []\noof_predict = np.zeros((train.shape[0],6))\nkf = KFold(n_splits=num_folds, shuffle=True, random_state=239)\nfor train_index, test_index in kf.split(x_train):\n    kfold_y_train,kfold_y_test = y_train[train_index], y_train[test_index]\n    kfold_X_train = x_train[train_index]\n    kfold_X_features = features[train_index]\n    kfold_X_valid = x_train[test_index]\n    kfold_X_valid_features = features[test_index] \n    gc.collect()\n    K.clear_session()\n    model = get_model(features)\n    ra_val = RocAucEvaluation(validation_data=([kfold_X_valid,kfold_X_valid_features], kfold_y_test), interval = 1)\n    model.fit([kfold_X_train,kfold_X_features], kfold_y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n             callbacks = [ra_val])\n    gc.collect()\n    model.load_weights(\"best_weights.h5\")\n    predict += model.predict([x_test,test_features], batch_size=batch_size,verbose=1) / num_folds\n    gc.collect() #- Running out of kaggle memory\n    oof_predict[test_index] = model.predict([kfold_X_valid, kfold_X_valid_features],batch_size=batch_size, verbose=1)\n    cv_score = roc_auc_score(kfold_y_test, oof_predict[test_index])\n    scores.append(cv_score)\n    print('Cross Validation Score: ',cv_score)\n\nprint(\"Model Completion for Keras DL\")\nprint('Total CV score is {}'.format(np.mean(scores)))   \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6bfd841fc54aaa500b520050eeb30aaf02157f6e"
      },
      "cell_type": "markdown",
      "source": "Now, we will make prediction on the sample submission file and save it to csv."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "2b6df9a10017c87c54ca989ea24e27d10b387106"
      },
      "cell_type": "code",
      "source": "print (\"Saving Predictions for offline upload\")\nsample_submission = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\")\nclass_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\nsample_submission[class_names] = predict\nsample_submission.to_csv('UdactiyAssignment_v1.csv',index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "52b9b444-4d2a-4507-9965-224ae88d52fb",
        "_uuid": "f269d6206590f6f40b6a6524d411b5b579546f97",
        "trusted": true
      },
      "cell_type": "code",
      "source": "print (\"Code Run Completed\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0343212a4fe495104a07307149bf19aefa2af073"
      },
      "cell_type": "markdown",
      "source": "We will now submit the file."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}