{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "JwpNZmafM2VV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "id": "qSWoxdEFNIuS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a0a771a4-ad82-4aaf-8ab3-5a5763b84e02"
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()\n",
        "\n",
        "# If you're using the old version of the course (check a path of notebook on Coursera, you'll see v1 or v2),\n",
        "# use setup_week2_old()."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-16 11:13:48--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-16 11:13:48 (58.9 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "P05TrM6xM2VY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "85b1d9e3-340e-470f-db41-fdf258f1381a"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5LXWuqQ0M2Vb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "SCwArz-_M2Vc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "T2c7ZPtwM2Ve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "22f31e9a-cca2-4567-9c18-52cf2f8387b2"
      },
      "cell_type": "code",
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "4gn4E8CQM2Vg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "fc189287-5f3f-440f-c4f4-c91caeb713f3"
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEHCAYAAACgHI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "EuBOiXwQM2Vi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "id": "P_dKP5bESKVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8734e08e-1b0e-4b50-fae8-be5eb9850172"
      },
      "cell_type": "code",
      "source": [
        "ll = ['abc', 'abd', 'xyz', 'xzk']\n",
        "{l for word in ll for l in word}"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a', 'b', 'c', 'd', 'k', 'x', 'y', 'z'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "FW95d4n_Tw5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "c93c0478-f45a-44c6-8f50-0f05f75bfaa4"
      },
      "cell_type": "code",
      "source": [
        "{l for word in names for l in word}"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ',\n",
              " \"'\",\n",
              " '-',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "dYcGv198M2Vj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fa81f751-85d0-4244-fbb4-a3042e9d6ae6"
      },
      "cell_type": "code",
      "source": [
        "tokens = [start_token+pad_token]+list({l for word in names for l in word})### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "print(len(tokens))\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56\n",
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1f5oPfu4M2Vl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "riHBlCpKM2Vl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "token_to_id = defaultdict(lambda:1,{token:i for i,token in enumerate(tokens)}) ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "twPIoNnaUuS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "3990a3e5-d20f-4075-8926-baff2d0f46a8"
      },
      "cell_type": "code",
      "source": [
        "token_to_id"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>>,\n",
              "            {' ': 1,\n",
              "             ' #': 0,\n",
              "             \"'\": 4,\n",
              "             '-': 3,\n",
              "             'A': 36,\n",
              "             'B': 48,\n",
              "             'C': 55,\n",
              "             'D': 38,\n",
              "             'E': 22,\n",
              "             'F': 14,\n",
              "             'G': 24,\n",
              "             'H': 30,\n",
              "             'I': 39,\n",
              "             'J': 29,\n",
              "             'K': 42,\n",
              "             'L': 18,\n",
              "             'M': 53,\n",
              "             'N': 52,\n",
              "             'O': 33,\n",
              "             'P': 34,\n",
              "             'Q': 21,\n",
              "             'R': 46,\n",
              "             'S': 9,\n",
              "             'T': 19,\n",
              "             'U': 50,\n",
              "             'V': 47,\n",
              "             'W': 25,\n",
              "             'X': 45,\n",
              "             'Y': 26,\n",
              "             'Z': 40,\n",
              "             'a': 5,\n",
              "             'b': 11,\n",
              "             'c': 28,\n",
              "             'd': 35,\n",
              "             'e': 2,\n",
              "             'f': 15,\n",
              "             'g': 6,\n",
              "             'h': 12,\n",
              "             'i': 37,\n",
              "             'j': 8,\n",
              "             'k': 51,\n",
              "             'l': 7,\n",
              "             'm': 32,\n",
              "             'n': 43,\n",
              "             'o': 49,\n",
              "             'p': 13,\n",
              "             'q': 54,\n",
              "             'r': 41,\n",
              "             's': 16,\n",
              "             't': 17,\n",
              "             'u': 23,\n",
              "             'v': 20,\n",
              "             'w': 27,\n",
              "             'x': 44,\n",
              "             'y': 31,\n",
              "             'z': 10})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "xJfYYS5gM2Vn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "ihVD3q5CM2Vr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f95a2cf3-789b-4f09-a4e5-66d1a1a980df"
      },
      "cell_type": "code",
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 1 36 11  5  6  5  2  7  1]\n",
            " [ 1 24  7 49 41 31  1  1  1]\n",
            " [ 1 34 41 37 16 16 37  2  1]\n",
            " [ 1 24 37 49 20  5 43 43  2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e49vQrTxM2Vt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "rwWSEn1TM2Vv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-wUnMhOYV_eC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9552a56e-845c-4398-cdfc-643cb6930ea5"
      },
      "cell_type": "code",
      "source": [
        "n_tokens"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "zNZdgHyTM2Vy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units,activation='tanh') ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens,activation='softmax') ### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h0SqNiggM2V0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "J1ME6BjFM2V1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb, h_t]) ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rQbguTs0M2V3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "BUrf5cTtM2V3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zLSE94FZM2V5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "DrU5GBR0M2V6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens) ### this is pulling the correct answers from the tensor > -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iWW-y1KdM2V7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "muOgjMarM2V8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix,predictions_matrix))\n",
        "### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kW3T_UGFM2V-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: training"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "5dPKWI6cM2V_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "6b97d746-166e-4464-8e74-e790cb9af02f"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_+\n",
        "      initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnARyIYQwOQnkQghhchLIhRDC5P4fCLWKsnuGBg0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "KGWf_YLkM2WC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "B34RDNKjM2WD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "W17ERnnEM2WF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "gJMmK0mHM2WJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "11e2ee1a-fb06-44f9-9786-805a67d73895"
      },
      "cell_type": "code",
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Sol            \n",
            " Tota           \n",
            " Lodop          \n",
            " Wenli  E       \n",
            " Durh lie       \n",
            " Darse          \n",
            " Catodir        \n",
            " Amdatne        \n",
            " Cardin         \n",
            " Malh           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "zT4MP0eZM2WL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5202ca96-e987-4fe1-a4fd-55aa3c9342e3"
      },
      "cell_type": "code",
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumped        \n",
            " Trumpean       \n",
            " Trumpae        \n",
            " Trumpas        \n",
            " Trumpins-      \n",
            " Trumpea        \n",
            " Trumpie        \n",
            " Trumpavarch    \n",
            " Trumponne      \n",
            " Trumpos        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ljkAOshIM2WN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "5owdgVN6M2WO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = 'OcuZRaD5BIv3ew8J' ### YOUR TOKEN HERE ###\n",
        "COURSERA_EMAIL = 'prateekgupta.nitjsr@gmail.com' ### YOUR EMAIL HERE ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "AWeTBNk_M2WQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "96a9143a-6c96-4f28-908c-54a26f870d0a"
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-xTo_N_5M2WT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "l4bPMcUmM2WT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "MfJq7Z-sM2WU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pGUg1k5qM2WW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "z63Ib8TpM2WW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "09u3Vhx9M2WY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}